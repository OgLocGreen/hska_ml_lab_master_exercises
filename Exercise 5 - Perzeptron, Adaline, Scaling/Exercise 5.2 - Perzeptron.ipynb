{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teil b - Perzeptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perzeptron-Lernalgorithmus\n",
    "\n",
    "<img src=\"../Figures/vorwaerts_und_rueckwaerts.png\" alt=\"drawing\" style=\"width:300px;\"/>\n",
    "\n",
    "### Vorwärtspfad und Rückwärtspfad\n",
    "Im vorherigen Teil wurde die Auswertung durch das Netz im Detail besprochen. <br>\n",
    "Der Vorwärtspfad besteht aus den folgenden Schritten:\n",
    "1. den Input $x_i$ bereitstellen.\n",
    "2. die gewichtete Summe $\\vec{w}^T \\cdot \\vec{x} +w_0$ berechnen.\n",
    "3. die Stufenfunktion anwenden.\n",
    "4. Output auswerten.\n",
    "\n",
    "Der Rückwärtspfad, welcher das Lernen des neuronalen Netzes betrifft, besteht aus den folgenden Schritten:\n",
    "1. Fehler ermitteln.\n",
    "2. Darauf basierend die Gewichte ändern.\n",
    "3. Input bei Berechnung des Fehlers miteinbeziehen.\n",
    "\n",
    "### Lernen in neuronalen Netzen\n",
    "Nachdem die Eingaben $\\vec{x}$ durch die Fragestellung vorgegeben sind, können in neuronalen Netzen nur die Gewichtungen angepasst werden. Dh. es geht um die Anpassung von Gewichten, wenn man von Lernen sprechen. Die Gewichte werden folgendermaßen angepasst.\n",
    "\n",
    "1. Dem Netz wird ein Lernbeispiel präsentiert.\n",
    "2. Berechnungen werden durchgeführt.\n",
    "3. Der Errechnete Wert $\\hat{y}$ wird mit dem gewünschten Wert y vergleichen.\n",
    "4. Basierend auf dem Unterschied des Vergleichs erfolgt die Anpassung der Gewichte.\n",
    "\n",
    "Das Netz sollte die Beispiele immer besser lernen und das gewünschte Ergebnis erzeugen. Jeder Durchgang (Epoche) sollte eine Verringerung des Fehlers bewirken. Das Verhalten nennt sich Konvergenz, die Regel Lernalgorithmus.\n",
    "\n",
    "Der Lernalgorithmus kann verbal folgendermaßen beschrieben werden:\n",
    "1. Initialisierung der Gewichtungen und des Schwellenwertes. Für die Initialisierung gibt es verschiedene Strategien, bspw. Werte im Intervall (-1,1).\n",
    "2. Wenn die errechnete Ausgabe eines Neurons und der gewünschte Wert übereinstimmen (z.b. 1 und 1), werden die Gewichte nicht verändert.\n",
    "3. Stimmen die Werte nicht überein: <br>\n",
    "3.a. Ist die Ausgabe 0 und der Wunschwert 1, so werden alle Gewichte erhöht. Dies geschieht, da der ermittelte Wert zu gering ist und eine Veränderung stattfinden muss. Das berechnete Ergebnis fällt somit höher aus. <br>\n",
    "3.b. Ist die Ausgabe 1 und der Wunschwert 0, so werden alle Gewichte verringert.\n",
    "\n",
    "\n",
    "### Perzeptron Lernalgorithmus\n",
    "\n",
    "Das mit einem Schwellenwert versehene Perzeptron-Modell beruht auf folgender Idee: entweder es feuert oder es feuert nicht. Die Perzeptron-Regel kann durch folgende Schritte zusammengefasst werden:\n",
    "1. Die Gewichtungen werden mit kleinen zufälligen Werten initialisiert.\n",
    "2. Mit jedem Trainingsobjekt $x^{(i)}$ werden folgende Schritte durchgeführt: <br>\n",
    "2.a Berechnung des Ausgabewertes $\\hat{y}$. <br>\n",
    "2.b Aktualisierung der Gewichtungen.\n",
    "\n",
    "Die Ausgabe entspricht die von der zuvor definierten Sprungfunktion vorhergesagte Klassenbezeichnung. Die gleichzeitige Aktualisierung der Gewichtungen $w_j$ im Gewichtungsvektor <b>w</b> wird folgendermaßen formal beschrieben:\n",
    "\n",
    "$s^{(i)} = \\vec{w}^T \\cdot \\vec{x}^{(i)} + w_0$ <br>\n",
    "$\\hat{y}^{(i)} = step(s^{(i)})$ <br>\n",
    "$E= y^{(i)} - \\hat{y}^{(i)}$ <br>\n",
    "$\\Delta w_j = \\eta \\cdot E $ <br>\n",
    "$w_j = w_j + \\Delta w_j \\cdot x_j^{(i)} $<br>\n",
    "\n",
    "\n",
    "$\\vec{w}$ der Gewichtsvektor <br>\n",
    "$\\vec{x}^{(i)}$ der <i>i-</i>te Input-Vektor <br>\n",
    "$w_0$ der Bias-Vektor <br>\n",
    "$s^{(i)}$ = gewichtete Summe <br>\n",
    "$E$ Error, Fehler <br>\n",
    "$y^{(i)}$ die gewünschte/ tatsächliche Klassenbezeichnung des <i>i</i>-ten Trainingsobjekts.<br>\n",
    "$\\hat{y}^{(i)}$ die vorhergesagte Klassenbezeichnung.<br>\n",
    "$\\Delta{w_j}$ bezeichnet die stattfindende Änderung des Gewichts $w_j$ und  wird zur Aktualisierung der Gewichtungen verwendet. <br>\n",
    "$\\eta$ Eta Lernrate (eine Konstante zwischen 0.0 und 1.0) <br>\n",
    "$w_j$ der <i>j</i>-te Gewichtsvektor  <br>\n",
    "$x_j^{(i)}$ der <i>j-</i>te Wert  <br>\n",
    "\n",
    "\n",
    "Es ist wichtig anzumerken, dass alle Gewichtungen im Gewichtungsvektor gleichzeitig aktualisiert werden, sodass $y^{(i)}$ nicht erneut berechnet werden muss, bevor alle Gewichtungen $\\Delta w_j$ aktualisiert wurde. <br>\n",
    "\n",
    "### Beispiele\n",
    "#### Allgemeines Beispiel\n",
    "\n",
    "In den beiden Szenarien, in denen das Perzeptron die Klassenbezeichnung korrekt vorhersagt, bleiben die Gewichtungen unverändert: <br>\n",
    "\n",
    "* $w_j = \\eta(-1--1) \\cdot x_j^{(i)} = 0.$\n",
    "* $w_j = \\eta(1-1) \\cdot x_j^{(i)} = 0.$\n",
    "\n",
    "Im Falle einer falschen Vorhersage werden die Gewichtungen in Richtung der positiven bzw. negativen Zielklasse verschoben: \n",
    "\n",
    "* $w_j = \\eta(1--1) \\cdot x_j^{(i)} = \\eta(2) \\cdot x_j^{(i)}.$\n",
    "* $w_j = \\eta(-1-1) \\cdot x_j^{(i)} = \\eta(-2) \\cdot x_j^{(i)}.$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Konkretes Beispiel 1\n",
    "\n",
    "Ein weiteres Beispiel um ein bessers Gespür für den multiplikativen Faktor $x_j^{(i)}$ zu bekommen: <br>\n",
    "\n",
    "Es gilt: $y^{(i)}$= +1; $\\hat{y}^{(i)}$ = -1; $\\eta$= 1.\n",
    "\n",
    "Angenommen $x_j^{(i)}$= 0.5 und dieses Objekt wird mit -1 klassifiziert. Somit ergibt sich folgende Berechnung zur Aktualisierung des Gewichts: <br>\n",
    "\n",
    "$\\Delta w_j = (1--1) \\cdot 0.5 = (2) \\cdot 0.5 = 1.$\n",
    "\n",
    "In diesem Fall wird die zugehörige Gewichtung um 1 erhöht. Somit wird die Nettoeingabe $x_j^{(i)} \\cdot w_j$ positiver, wenn das nächste Mal auf das Objekt getroffen wird. Und somit die Wahrscheinlichkeit erhöht, dass der Schwellenwert der Sprungfunktion überschritten und das Objekt als +1 klassifiziert wird. Die Aktualisierung der Gewichtungen erfolgt proportional zum Wert $x_j^{(i)}$.\n",
    "\n",
    "#### Konkretes Beispiel 2\n",
    "Weiteres Beispiel: \n",
    "$x_j^{(i)}$=2 wird irrtürmlich als -1 klassifiziert. Update-Berechnung wiefolgt:\n",
    "$\\Delta w_j = (1--1) \\cdot 2 = (2) \\cdot 2 = 4.$ <br>\n",
    "Die Aktualisierung des Objekts erfolgt sogar noch stärker.\n",
    "\n",
    "\n",
    "### Zusammenfassung\n",
    "Folgende Abbildung illustriert die Funktionsweise des Perzeptrons:\n",
    "* nimmt Eingabe $\\vec{x}$ entgegen.\n",
    "* kombiniert diese mit den Gewichtungen $\\vec{w}$.\n",
    "* berechnet die Nettoeingabefunktion.\n",
    "* diese wird an Aktivierungsfunktion (hier: Heaviside-Funktion) übergeben.\n",
    "* erzeugt binäre Ausgabe: 0 oder 1.\n",
    "* dies entspricht der Vorhersage für die Klassenbezeichnung.\n",
    "* Während der Lernphase wird die Ausgabe genutzt, um\n",
    "* a) den Fehler festzustellen\n",
    "* b) die Gewichtungen zu aktualisieren\n",
    "\n",
    "<img src=\"../Figures/Perzeptron.png\" alt=\"drawing\" style=\"width:600px;\"/>\n",
    "\n",
    "\n",
    "Es gilt zu beachten, dass die Konvergenz des Perzeptrons nur dann gewährleistet ist, wenn beide Klassen linear trennbar sind. Sollte dies nicht der Fall sein, kann eine maximale Anzahl an Durchläufen der Trainingsdaten (Epochen) oder ein Schwellenwert für die Anzahl der Fehlklassifizierungen definiert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementierung\n",
    "\n",
    "Die Implementierung erfolgt innerhalb der Klasse <b>Perceptron</b>. Im folgenden werden die einzelnen Methoden und deren Funktionsweise kurz vorgestellt. <br>\n",
    "\n",
    "### Konstruktor\n",
    "Das Perceptron-Objekt wird mit der Lernrate <b>eta</b> und der Anzahl der Epochen (Durchläufe der Trainingsdaten) <b>epochs</b> initialisiert. Wählen Sie geeignete Werte für die Epoche (Anzahl der Durchläufe) und die Lernrate Eta.\n",
    "\n",
    "### gewichtete_summe()-Methode:\n",
    "In dieser Methode soll die beschriebene gewichtete Summe $\\vec{w}^T \\cdot \\vec{x} + w_0$ berechnet werden. Zur Berechnung des Skalarprodukts zweier Arrays ergeben sich zwei Möglichkeiten. <br>\n",
    "\n",
    "* Python: via <b>sum(...)</b>. Berechnung wird mit den einzelnen Elementen durchgeführt.<br>\n",
    "* Numpy: via <b>np.dot(a,b)</b>. Hat den Vorteil, dass arithmetische Operationen vektorisiert sind. Vektorisierung bedeutet, dass arithmetische Operationen automatisch auf alle Elemente eines Arrays angewendet werden. Durch die Formulierung der arithmetischen Operationen als eine Reihe von Array-Rechenanweisungen kann die Fähigkeit moderner CPUs besser genutzt werden. Darüber hinaus verwendet Numpy hochoptimierte Bibliotheken für lineare Algebra wie bspw. BLAS und LAPACK, welche in C oder Fortran implementiert sind.<br>\n",
    "\n",
    "\n",
    "### heaviside()-Methode:\n",
    "Implementierung der Heaviside-Funktion. Parameter ist die gewichtete Summe . Es soll die vorhergesagte Klassenbezeichnungen für den Eingangsvektor $\\vec{x}$  ermittelt werden. \n",
    "\n",
    "### fit()-Methode:\n",
    "\n",
    "<b>Gewichtungen</b>: <br>\n",
    "\n",
    "Die Gewichtungen in <b>w</b> werden mit einem Vektor $\\mathbb R^{m+1}$ initialisiert, m gibt die Anzahl der Dimensionen (Merkmale) in der Datensammlung an. Dem ersten Element dieses Vektors (dies entspricht der Bias-Einheit) wird der Wert 1 zugeordnet. Gehen Sie von zwei Merkmalen aus (weiter unten wird die Datenstruktur beschrieben).<br>\n",
    "\n",
    "Die Gewichtungen werden nicht mit null initialisiert, weil sich die Lernrate Eta $\\eta$ nur dann auf das Ergebnis der Klassifizierung auswirkt, wenn die Gewichtungen von Null verschiedene Werte besitzt. <br>\n",
    "\n",
    "Überlegen Sie sich geeignete Initialisierungswerte für die Gewichtungen. Bspw. können die Werte der Gewichtungen einer Normalverteilung entnommen werden. Als Standardabweichung kann hierbei 0.01 dienen. <br>\n",
    "\n",
    "Hinweis: die Normalverteilung kann via <b>np.random.normal</b> oder <b>np.random.RandomState</b> und <b>randomstate.rgen.normal</b> erzeugt werden.\n",
    "\n",
    "<b>Funktionsweise</b>: <br>\n",
    "\n",
    "In dieser Methode soll das Training des neuronalen Netzes umgesetzt werden. <br>\n",
    "\n",
    "Pro Epoche werden alle Trainingsobjekte durchlaufen und die Gewichtungen gemäß der Perzeptron-Lernregel aktualisiert. Innerhalb der <b>fit()</b>-Methode werden die zuvor definierten Methoden aufgerufen, um die Klassenbezeichnung für die Aktualisierung der Gewichtungen vorherzusagen und die Gewichtungen zu aktualisieren. <br>\n",
    "\n",
    "Sammeln Sie in einer Liste <b>errors</b> die in jeder Epoche auftretenden Fehlklassifizierungen. Dadurch kann später analysiert werden, wie gut das Perzeptron während des Trainings funktioniert hat. Geben Sie diese Liste als Rückgabewert der Methode zurück.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    \n",
    "    def __init__(self, eta=None, epochs=None):\n",
    "        # TODO : implement\n",
    "        pass\n",
    "        \n",
    "    def gewichtete_summe(self, x):\n",
    "        # TODO: implement\n",
    "        return None \n",
    "        \n",
    "    def heaviside(self, summe):\n",
    "        # TODO: implement\n",
    "        return None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # TODO: implement\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datensatz\n",
    "\n",
    "### Möglichkeit 1): Iris-Datensatz manuell reduzieren.\n",
    "\n",
    "Für die folgende Implementierung wird der Iris-Datensatz verwendet. Dieser ist unter /Data abgelegt. Lesen Sie den Datensatz ein.\n",
    "\n",
    "Zur Implementierung werden je zwei Klassen und zwei Merkmale des Iris-Datensatz als zweidimensionalen Merkmalsraum verwendet. Dies geschieht aus praktischen Gründen wie bspw. die Nachvollziehbarkeit der Werte und die Visualisierung der Merkmale.\n",
    "Selektieren Sie aus dem Datensatz die beiden Klassen *Setosa* und *Versicolor* und  hiervon die beiden Merkmale \"Länge des Kelchblatts\" und \"Länge des Blütenblatts\". \n",
    "\n",
    "Wählen Sie für die Bestimmung der Eingabematrix <b>X</b> die Merkmale Kelch- und Bluetenblattlaenge (Sepal Length und Petal Length) aus. Wählen für die Bestimmung des Zielvektors $\\vec{y}$ die Werte von setosa und versicolor. Setzen Sie hierfür eine Zielvariable auf 1, die andere auf 0.\n",
    "\n",
    "Visualisieren Sie den entstandenen Merkmalsraum, so dass die verschiedenen Zielvariablen unterscheidbar sind.\n",
    "\n",
    "### Möglichkeit 2): Iris-Datensatz aus PCA-Dimensionsreduktion.\n",
    "Alternativ können Sie die erzeugten Komponenten aus dem PCA-Aufgabenblatt verwenden. Somit führen Sie die Prozesskette durch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None # TODO: implement\n",
    "\n",
    "\n",
    "# Auswahl von setosa und versicolor\n",
    "y = None # TODO: implement \n",
    "\n",
    "# Auswahl von Kelch- und Bluetenblattlaenge\n",
    "X = None # TODO: implement\n",
    "\n",
    "# Diagramm ausgeben\n",
    "# TODO: implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Beispiel: <br>\n",
    "<img src=\"../Figures/Sepal-Length-Petal-Length.png\" alt=\"drawing\" style=\"width:400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training und Visualisierung des Errors\n",
    "\n",
    "Führen Sie das Training anhand der Perzeptron-Klasse und der <b>fit</b>-Methode mit unterschiedlichen Parametern für die Epoche (bspw. 10, 30, 100, etc.) und die Lernrate (bspw. 1, 0.01, 0.00000001, etc.) durch. Visualisieren Sie die von der <b>fit</b>-Methode zurückgegebenen Errors in einem Plot (d.h. x-Achse=Epochen; y-Achse=Fehler). Dieser Plot ist von großer Bedeutung. Hierbei können Sie die Leistungsfähigkeit Ihrer Implementierung prüfen.\n",
    "\n",
    "Vergleichen Sie die Ergebnisse mit den unterschiedlich gewählten Parametern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beispiel Error-Plot: <br>\n",
    "\n",
    "<img src=\"../Figures/example-error-plot.png\" alt=\"drawing\" style=\"width:400px;\"/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
